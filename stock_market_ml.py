# -*- coding: utf-8 -*-
"""Stock Market ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eC4AVNSoCnfvze6GswF9KfJTqtZLR6au

# **Downloading S&P 500 Price Data**
"""

# Import the yfinance library, which allows us to interact with Yahoo Finance data
import yfinance as yf

# Assign the ticker symbol "^GSPC" (S&P 500) to the variable sp500
sp500 = yf.Ticker("^GSPC")

# Retrieve historical data for the S&P 500 (sp500) using the .history() method
# Set the period parameter to "max" to fetch data for the maximum available time period
sp500 = sp500.history(period="max")

sp500.head()

sp500.tail()

sp500.index

"""# **Cleaning And Visualizing Stock The Market Data**"""

# Plot a line chart using the historical data of the S&P 500 (sp500)
# Select the "Close" column for the y-axis data
# Use the index of the DataFrame for the x-axis data
sp500.plot.line(y="Close", use_index=True)

# Delete the "Dividends" column from the sp500 DataFrame
del sp500["Dividends"]

# Delete the "Stock Splits" column from the sp500 DataFrame
del sp500["Stock Splits"]

# Display the first few rows of the modified sp500 DataFrame
sp500.head()

sp500.head()

# Create a new column named "Tomorrow" in the sp500 DataFrame
# Shift the "Close" column up by one row to represent tomorrow's closing prices
sp500["Tomorrow"] = sp500["Close"].shift(-1)

# Display the sp500 DataFrame with the new "Tomorrow" column
sp500

# Create a new column named "Target" in the sp500 DataFrame
# Assign 1 to the "Target" column where tomorrow's closing price is greater than today's closing price, else assign 0
sp500["Target"] = (sp500["Tomorrow"] > sp500["Close"]).astype(int)

# Display the sp500 DataFrame with the new "Target" column
sp500

# Filter the sp500 DataFrame to include data from January 1, 1990, onwards
# Use .loc[] to select rows based on index labels and .copy() to create a copy of the filtered DataFrame
sp500 = sp500.loc["1990-01-01":].copy()

# Display the filtered sp500 DataFrame
sp500

"""# **TRAINING AN INITIAL MACHINE LEARNING MODEL**"""

# Import the RandomForestClassifier class from the sklearn.ensemble module
from sklearn.ensemble import RandomForestClassifier

# Create a RandomForestClassifier model with specified parameters
# n_estimators defines the number of trees in the forest
# min_samples_split is the minimum number of samples required to split an internal node
# random_state is the seed used by the random number generator
model = RandomForestClassifier(n_estimators=100, min_samples_split=100, random_state=1)

# Split the sp500 DataFrame into a training set (train) and a testing set (test)
# train contains data except for the last 100 rows
train = sp500.iloc[:-100]
# test contains the last 100 rows of data
test = sp500.iloc[-100:]

# Define the predictors used for training the model
predictors = ["Close", "Open", "High", "Low", "Volume"]

# Train the RandomForestClassifier model using the training data
# model.fit() takes the predictors (features) and the target variable (labels) from the training set
model.fit(train[predictors], train["Target"])

# Import the precision_score function from the sklearn.metrics module
from sklearn.metrics import precision_score

# Use the trained model to make predictions on the test data
# model.predict() takes the predictors (features) of the test set as input and returns the predicted labels
preds = model.predict(test[predictors])

# Import the pandas library and alias it as pd
import pandas as pd

# Create a pandas Series called preds using the predicted labels and using the index from the test data
preds = pd.Series(preds, index=test.index)

preds

# Calculate the precision score by comparing the actual target labels (test["Target"])
# with the predicted labels (preds) using the precision_score function
precision_score(test["Target"], preds)

# Combine the actual target labels (test["Target"]) and the predicted labels (preds) into a DataFrame
# Use pd.concat() function to concatenate along the columns (axis=1)
combined = pd.concat([test["Target"], preds], axis=1)

combined.plot()

# Define a function named predict that takes four parameters:
# - train: DataFrame containing training data
# - test: DataFrame containing testing data
# - predictors: list of features used for prediction
# - model: machine learning model used for prediction
def predict(train, test, predictors, model):
    # Train the model using the training data
    model.fit(train[predictors], train["Target"])
    # Make predictions on the test data
    preds = model.predict(test[predictors])
    # Create a pandas Series containing the predicted labels with index from the test data
    preds = pd.Series(preds, index=test.index, name="Predictions")
    # Combine the actual target labels and the predicted labels into a DataFrame
    combined = pd.concat([test["Target"], preds], axis=1)
    # Return the combined DataFrame
    return combined

# Define a function named backtest that takes five parameters:
# - data: DataFrame containing the entire dataset
# - model: machine learning model used for prediction
# - predictors: list of features used for prediction
# - start: starting index for backtesting (default value: 2500)
# - step: size of each backtesting step (default value: 250)
def backtest(data, model, predictors, start=2500, step=250):
    # Initialize an empty list to store predictions from each backtesting step
    all_predictions = []

    # Iterate through the data starting from the specified start index with a specified step size
    for i in range(start, data.shape[0], step):
        # Slice the data to create training and testing sets for the current backtesting step
        train = data.iloc[0:i].copy()  # Training set includes data from the beginning up to i
        test = data.iloc[i:(i+step)].copy()  # Testing set includes data from i to (i+step)

        # Generate predictions for the current backtesting step using the predict function
        predictions = predict(train, test, predictors, model)

        # Append the predictions for the current step to the list
        all_predictions.append(predictions)

    # Concatenate all predictions from different backtesting steps into a single DataFrame
    return pd.concat(all_predictions)

# Perform backtesting using the backtest function with the specified parameters
predictions = backtest(sp500, model, predictors)

# Count the occurrences of each unique value in the "Predictions" column of the predictions DataFrame
predictions["Predictions"].value_counts()

# Calculate the precision score by comparing the actual target labels ("Target")
# with the predicted labels ("Predictions") in the predictions DataFrame
precision_score(predictions["Target"], predictions["Predictions"])

# Calculate the proportion of each unique value in the "Target" column of the predictions DataFrame
# Divide the counts of each unique value by the total number of rows in the predictions DataFrame
predictions["Target"].value_counts() / predictions.shape[0]

"""# **ADDING ADDITIONAL PREDICTORS TO THE MODEL**"""

# Define a list of different time horizons
horizons = [2, 5, 60, 250, 1000]

# Initialize an empty list to store the new predictor column names
new_predictors = []

# Iterate through each time horizon
for horizon in horizons:
    # Calculate rolling averages over the specified horizon for the entire sp500 DataFrame
    rolling_averages = sp500.rolling(horizon).mean()

    # Create a new column for the close ratio for the current horizon
    ratio_column = f"Close_Ratio_{horizon}"
    sp500[ratio_column] = sp500["Close"]

    # Create a new column for the moving average of the close ratio for the current horizon

sp500 = sp500.dropna()

sp500

"""# **IMPROVING THE MODEL**"""

# Create a RandomForestClassifier model with the following parameters:
# - n_estimators: the number of trees in the forest (200)
# - min_samples_split: the minimum number of samples required to split an internal node (50)
# - random_state: the seed used by the random number generator for reproducibility (1)
model = RandomForestClassifier(n_estimators=200, min_samples_split=50, random_state=1)

# Define a function named predict that takes four parameters:
# - train: DataFrame containing training data
# - test: DataFrame containing testing data
# - predictors: list of features used for prediction
# - model: machine learning model used for prediction
def predict(train, test, predictors, model):
    # Train the model using the training data
    model.fit(train[predictors], train["Target"])
    # Make probability predictions on the test data
    preds = model.predict_proba(test[predictors])[:, 1]
    # Apply a threshold of 0.6 to convert probabilities to binary predictions
    preds[preds >= 0.6] = 1
    preds[preds < 0.6] = 0
    # Create a pandas Series containing the binary predictions with index from the test data
    preds = pd.Series(preds, index=test.index, name="Predictions")
    # Combine the actual target labels and the binary predictions into a DataFrame
    combined = pd.concat([test["Target"], preds], axis=1)
    # Return the combined DataFrame
    return combined

# Perform backtesting using the backtest function with the specified parameters
predictions = backtest(sp500, model, new_predictors)

# Count the occurrences of each unique value in the "Predictions" column of the predictions DataFrame
predictions["Predictions"].value_counts()

precision_score(predictions["Target"], predictions["Predictions"])

"""# **SUMMARY AND NEXT STEPS WITH THE MODEL**

-Consider the news and articules coming out about the stock market

-Knowledge of macroeconomics variables such as interest and inflation rate

-Addition of other key components

-increasing the resolution (hourly,  daily, weekly) data
"""